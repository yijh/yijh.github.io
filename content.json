{"meta":{"title":"呆子萌的","subtitle":null,"description":null,"author":"呆子萌的","url":"http://yoursite.com"},"pages":[{"title":"tags","date":"2016-12-13T02:46:37.000Z","updated":"2016-12-13T02:53:05.925Z","comments":false,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""},{"title":"about","date":"2016-12-13T02:47:48.000Z","updated":"2016-12-13T02:52:53.167Z","comments":false,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":""},{"title":"categories","date":"2016-12-13T02:46:52.000Z","updated":"2016-12-13T02:52:59.750Z","comments":false,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"Hive基础-分区表、桶","slug":"Hive基础-分区表、桶","date":"2016-12-08T07:36:32.736Z","updated":"2016-12-13T02:45:08.750Z","comments":true,"path":"2016/12/08/Hive基础-分区表、桶/","link":"","permalink":"http://yoursite.com/2016/12/08/Hive基础-分区表、桶/","excerpt":"","text":"分区表Hive中没有复杂的分区类型（List,Range,Hash）、各种复合分区，分区列不是表中的实际字段而是一个伪列，创建表时可以指定PARTITION BY 子句创建一个或多个分区，每个分区在HDFS中会自动创建一个独立的文件夹。分区键不能和列名同名，不然会报 “FAILED: Error in semantic analysis: Column repeated in partitioning columns,”Hive中分区表分两类：静态分区、动态分区； 静态分区Hive默认是静态分区，静态分区在插入数据时需要指定分区键值，好让数据插入指定分区中 12345678910CREATE TABLE IF NOT EXISTS part_person (id string,name string)PARTITIONED BY (date string)STORED AS TEXTFILE;insert into part_person PARTITION(date='2016-11-11') values('2','ss1');insert into part_person PARTITION(date='2016-11-13') values('3','ss2'); 动态分区如果数据量很大，每条插入语句都要指定键值很麻烦，于是就有了动态分区，让Hive自动根据数据插入到指定分区内。 123456789101112131415161718192021222324252627282930创建普通表，并插入测试数据CREATE TABLE IF NOT EXISTS person (id int,name string,dt string,country string) STORED AS TEXTFILE;insert into person values(1,'dd','2016-11-11','jp');insert into person values(2,'ee','2016-11-22','cn');insert into person values(3,'gg','2016-11-14','jp');insert into person values(4,'ff','2016-11-11','cn');insert into person values(5,'tt','2016-11-22','jp');insert into person values(6,'aa','2016-11-14','cn');insert into person values(7,'bb','2016-11-11','cn');insert into person values(8,'ss','2016-11-14','jp');insert into person values(9,'gg','2016-11-11','cn');insert into person values(10,'sr','2016-11-22','cn');insert into person values(11,'4e','2016-11-11','jp');insert into person values(12,'g5','2016-11-14','cn');insert into person values(13,'1hg','2016-11-14','cn');insert into person values(14,'haf','2016-11-22','jp');insert into person values(15,'jhj','2016-11-14','cn');insert into person values(16,'xc','2016-11-22','cn');insert into person values(17,'nb','2016-11-11','jp');insert into person values(18,'2ds','2016-11-22','jp');insert into person values(19,'jse','2016-11-11','jp');insert into person values(20,'ngh','2016-11-22','cn');insert into person values(21,'aw4','2016-11-11','jp');insert into person values(22,'4st','2016-11-14','cn');创建一个有两个分区的分区表CREATE TABLE IF NOT EXISTS person_d_p (id int,name string) PARTITIONED BY (dt string,country string) STORED AS TEXTFILE; 123456使用INSERT INTO SELECT 插入数据hive&gt; INSERT INTO person_d_p PARTITION(dt,country) SELECT * FROM person;FAILED: SemanticException [Error 10096]: Dynamic partition strict mode requires at least one static partition column. To turn this off set hive.exec.dynamic.partition.mode=nonstrict 报错说明需要设置动态分区模式，使用动态分区需要设置以下参数：hive.exec.dynamic.partition默认值：false使用动态分区必须设置为true hive.exec.dynamic.partition.mode默认值：strict表示至少需要一个静态分区，一般使用nonstrict，既所有分区都是动态分区 hive.exec.max.dynamic.partitions.pernode默认值：100每个MR节点允许创建的最大分区数，如果实际的分区数超过设置的值会报错Fatal error occurred when node tried to create too many dynamic partitions. hive.exec.max.dynamic.partitions默认值：1000一个动态分区语句，在所有节点允许创建的最大分区数，同上 hive.exec.max.created.files默认值：100000所有节点可以创建的最大文件数，根据需要调整 根据需要设置参数 123456SET hive.exec.dynamic.partition=true; SET hive.exec.dynamic.partition.mode=nonstrict; SET hive.exec.max.dynamic.partitions.pernode=1000;SET hive.exec.max.dynamic.partitions=10000;INSERT INTO person_d_p PARTITION(dt,country) SELECT * FROM person; 123456789101112131415显示所有分区hive&gt; show partitions person_d_p;OKdt=2016-11-11/country=cndt=2016-11-11/country=jpdt=2016-11-14/country=cndt=2016-11-14/country=jpdt=2016-11-22/country=cndt=2016-11-22/country=jpTime taken: 0.034 seconds, Fetched: 6 row(s)显示指定分区hive&gt; show partitions person_d_p partition(dt='2016-11-14',country='cn');OKdt=2016-11-14/country=cn 动态分区和静态分区还有一点区别就是静态分区不管有没有数据插入一定会创建分区，动态分区只有在插入数据的时候才创建分区；动态分区会为每个分区创建一个reduce任务，当分区数比较多时，需要设置合理的mapred.reduce.tasks参数，以避免直接把集群搞挂掉 桶Hive允许对表和分区以bucket的形式进一步划分数据，这在对表进行JOIN操作和数据采样（sampling）时能获得较高的性能，如果两个表的JOIN字段都分桶了，在JOIN时将大大减少读取的数据量；可以对一个以上的列分桶，分桶的方式采用对列值HASH除以桶的个数求余来决定数据落在哪个桶里。 123456789CREATE TABLE IF NOT EXISTS person_bkt(id int,name string,country string,dt string) CLUSTERED BY(country) SORTED BY (id) INTO 4 BUCKETSSTORED AS TEXTFILE; 创建桶时以CLUSTERED BY 子句指定字段，多个字段以逗号分隔；SORTED BY子句指定桶里的数据以哪个字段排序，默认为升序；INTO 指定分多少个桶。需要注意的是，SORTED BY并不会在插入数据时进行排序，需要显式指定排序加载数据需要开启下面参数 1set hive.enforce.bucketing=true; 向桶里载入数据，需要指定order by 子句，且排序字段与建表SORTED BY 字段一致 1INSERT INTO person_bkt SELECT id,name,country,dt FROM person order by id; 查看hdfs目录，发现有4个文件 123456hive&gt; dfs -ls /user/hive/warehouse/person_bkt;Found 4 items-rwxrwxrwt 3 root hive 0 2016-11-16 17:41 /user/hive/warehouse/person_bkt/000000_0-rwxrwxrwt 3 root hive 0 2016-11-16 17:41 /user/hive/warehouse/person_bkt/000001_0-rwxrwxrwt 3 root hive 200 2016-11-16 17:41 /user/hive/warehouse/person_bkt/000002_0-rwxrwxrwt 3 root hive 239 2016-11-16 17:41 /user/hive/warehouse/person_bkt/000003_0 但是实际只有两个文件有数据，因为country字段只有两组数据‘cn’和‘jp’查询数据，数据是以country分组，id升序排列 12345678910111213141516171819202122232425hive&gt; select * from person_bkt;OK1 dd jp 2016-11-113 gg jp 2016-11-145 tt jp 2016-11-228 ss jp 2016-11-1411 4e jp 2016-11-1114 haf jp 2016-11-2217 nb jp 2016-11-1118 2ds jp 2016-11-2219 jse jp 2016-11-1121 aw4 jp 2016-11-112 ee cn 2016-11-224 ff cn 2016-11-116 aa cn 2016-11-147 bb cn 2016-11-119 gg cn 2016-11-1110 sr cn 2016-11-2212 g5 cn 2016-11-1413 1hg cn 2016-11-1415 jhj cn 2016-11-1416 xc cn 2016-11-2220 ngh cn 2016-11-2222 4st cn 2016-11-14Time taken: 0.03 seconds, Fetched: 22 row(s) 桶数据抽样分桶之后怎么查？Hive提供了tablesample关键字进行数据抽样，可以对桶里的数据进行抽样查询 1select * from person_bkt tablesample (bucket 2 out of 4 on id); 2代表从第几个桶开始，4代表取多少个桶，必须是桶总数的倍数，可以使用desc formatted tablename 查看表的桶数量，详细的抽样查询在后面介绍。","categories":[{"name":"Hive","slug":"Hive","permalink":"http://yoursite.com/categories/Hive/"}],"tags":[{"name":"Hive","slug":"Hive","permalink":"http://yoursite.com/tags/Hive/"}]},{"title":"Hive基础-创建数据库-创建表","slug":"Hive基础-创建数据库-创建表","date":"2016-12-08T07:36:32.732Z","updated":"2016-12-13T06:34:06.613Z","comments":true,"path":"2016/12/08/Hive基础-创建数据库-创建表/","link":"","permalink":"http://yoursite.com/2016/12/08/Hive基础-创建数据库-创建表/","excerpt":"","text":"1.创建/删除/修改 数据库创建数据库1234CREATE (DATABASE|SCHEMA) [IF NOT EXISTS] database_name [COMMENT database_comment] [LOCATION hdfs_path] [WITH DBPROPERTIES (property_name=property_value, ...)]; LOCATION 指定数据存储在HDFS的路径WITH DBPROPERTIES 可设置KV格式的数据库属性，KEY可以自定义 1234CREATE DATABASE IF NOT EXISTS TEST COMMENT 'THIS IS TEST DATABASE' LOCATION '/USER/ROOT/' WITH DBPROPERTIES('CREATOR'='XXX','DATE'='2016-11-12'); 删除数据库1DROP (DATABASE|SCHEMA) [IF EXISTS] database_name [RESTRICT|CASCADE]; 默认情况下Hive不允许删除表里有数据的数据库，使用CASCADE会在删除数据库时删除该库下的所有对象，RESTRICT既为默认情况设置. 修改数据库12ALTER (DATABASE|SCHEMA) database_name SET DBPROPERTIES (property_name=property_value, ...);ALTER (DATABASE|SCHEMA) database_name SET OWNER [USER|ROLE] user_or_role; 2.创建/删除/截断表创建表12345678910111213141516CREATE [TEMPORARY] [EXTERNAL] TABLE [IF NOT EXISTS] [db_name.]table_name [(col_name data_type [COMMENT col_comment], ...)] [COMMENT table_comment] [PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)] [CLUSTERED BY (col_name, col_name, ...) [SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS] [SKEWED BY (col_name, col_name, ...) ON ((col_value, col_value, ...), (col_value, col_value, ...), ...) [STORED AS DIRECTORIES] [ [ROW FORMAT row_format] [STORED AS file_format] | STORED BY 'storage.handler.class.name' [WITH SERDEPROPERTIES (...)] ] [LOCATION hdfs_path] [TBLPROPERTIES (property_name=property_value, ...)] [AS select_statement]; 设置行、字段分隔符行与字段分隔符可让Hive在从文件加载数据时明确数据是怎么分隔的，具体设置方法如下： 12设置字段分隔符ROW FORMAT DELIMITED FIELDS TERMINATED BY char Hive 默认使用’\\001’，’\\001’代表控制符，用ctrl+v然后再ctrl+a可以输入这个控制符；分隔符可用八进制ASCII码表示，或者直接写字符，不过特殊字符需要转义，如空格’\\t’，换行’\\n’。 12设置转义符ROW FORMAT DELIMITED FIELDS ESCAPED BY char 如果字段中有些符号需要保留，可以用ESCAPED BY设置转义符。 12设置行分隔符LINES TERMINATED BY char 一般设置为 ‘\\n’ 内部表表的元数据和数据都由Hive维护，创建表时会自动在HDFS的/user/hive/warehouse 目录下创建与表同名的文件夹，删除表时HDFS上的数据和文件夹会删除 1234CREATE TABLE IF NOT EXISTS person (id int COMMENT '编号',name string COMMENT '姓名') COMMENT '人员表' STORED AS TEXTFILE; 外部表（EXTERNAL）删除表时只删除元数据，HDFS上的数据和文件夹保留，创建表时如果指定了HDFS的路径，则数据文件会直接存在指定路径下；如果创建表时不指定HDFS路径，会默认在/user/hive/warehouse目录创建表文件夹。 12345CREATE EXTERNAL TABLE IF NOT EXISTS person (id int COMMENT '编号',name string COMMENT '姓名') COMMENT '人员表' STORED AS TEXTFILE LOCATION '/user/hdfs/'; 临时表（TEMPORARY）临时表的数据和元数据都由Hive维护，只对当前Session有效,Session退出时表自动删除; 12345CREATE TEMPORARY TABLE IF NOT EXISTS person_tmp (id int COMMENT '编号',name string COMMENT '姓名') COMMENT '人员临时表' STORED AS TEXTFILE LOCATION '/user/hdfs/'; Create Table As Select (CTAS)Create Table 部分使用Select的查询结果创建目标表，且可以指定SerDe 和存储格式，不过也存在以下限制：1）要创建的表不能是分区表；2）要创建的表不能是外部表；3）要创建的表不能是List Bucketing表。 12345CREATE TABLE new_person ROW FORMAT SERDE \"org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe\" STORED AS RCFile AS select id,name from person; Create Table LikeCreate Table table1 Like table2 会创建与table2 结构完全相同的table1，通常用于复制表结构但不复制数据。 创建表的参数很多，有些涉及到存储格式、压缩、表的属性等内容，后面的文章会逐一说明。 删除表1DROP TABLE [IF EXISTS] table_name [PURGE]; 如果被删除的表有视图引用，在删除时不会警告，需要手动检查或重建视图如果指定了PURGE,删除表时数据会从HDFS上完全清除，而不会转入回收站 截断表123TRUNCATE TABLE table_name [PARTITION partition_spec];partition_spec: : (partition_column = partition_col_value, partition_column = partition_col_value, ...) 截断表会清空表里的数据，也可以指定清空特定分区","categories":[{"name":"Hive","slug":"Hive","permalink":"http://yoursite.com/categories/Hive/"}],"tags":[{"name":"Hive","slug":"Hive","permalink":"http://yoursite.com/tags/Hive/"}]},{"title":"Hive基础-数据类型","slug":"Hive基础-数据类型","date":"2016-12-08T07:36:32.720Z","updated":"2016-12-13T02:44:51.950Z","comments":true,"path":"2016/12/08/Hive基础-数据类型/","link":"","permalink":"http://yoursite.com/2016/12/08/Hive基础-数据类型/","excerpt":"","text":"Hive既有大多数关系数据库中的基本类型，又有集合这种复杂类型。 基本类型 数据类型 大小 范围 示例 TINYINT 1byte -128 ~ 127 100Y SMALLINT 2byte -32,768 ~ 32,767 100S INT/INTEGER 4byte -2,147,483,648 ~ 2,147,483,647 100 BIGINT 8byte -9,223,372,036,854,775,808 ~ 9,223,372,036,854,775,807 100L FLOAT 4byte 单精度浮点数 3.1415926 DOUBLE 8byte 双精度浮点数 3.1415926 DECIMAL - 高精度浮点数 DECIMAL(9,8) BOOLEAN - 布尔型，TRUE/FALSE true BINARY - 二进制类型 - 数字类型整数类型-2,147,483,648 ~ 2,147,483,647之间的整数类型默认是INT型，除非指定了格式100Y、100S、100L会自动转换为TINYINT、SMALLINT、BIGINT 浮点数类型浮点数默认会当作DOUBLE型；Hive中的DECIMAL基于Java中的BigDecimal，BigDecimal用于表示任意精度的不可修改的十进制数字；DECIMAL不指定精度时默认为DECIMAL(10,0)； 字符串类型Stringstring类型可以用单引号（’）或双引号（”）定义，Hive在string中使用C-style。Varcharvarchar类型由长度定义，范围为1-65355，如果存入的字符串长度超过了定义的长度，超出部分会被截断。尾部的空格也会作为字符串的一部分，影响字符串的比较。Charchar是固定长度的，最大长度255，而且尾部的空格不影响字符串的比较。三种类型对尾部空格的区别，参考如下例子，每个字段都插入同样的字符并且在尾部有不同的空格。 1234567create table char_a (c1 char(4),c2 char(5),str1 string,str2 string,var1 varchar(4),var2 varchar(6));insert into char_a values('ccc ','ccc ','ccc ','ccc ','ccc ','ccc ');select c1=c2,str1=str2,var1=var2 from char_a;OKtrue false falseTime taken: 1.101 seconds, Fetched: 1 row(s) 日期与时间戳Timestampstimestamp表示UTC时间，可以是以秒为单位的整数；带精度的浮点数，最大精确到小数点后9位，纳秒级；java.sql.Timestamp格式的字符串 YYYY-MM-DD hh:mm:ss.fffffffffDateHive中的Date只支持YYYY-MM-DD格式的日期，其余写法都是错误的，如需带上时分秒，请使用timestamp 复杂类型STRUCT类似于C、C#语言，Hive中定义的struct类型也可以使用点来访问。从文件加载数据时，文件里的数据分隔符要和建表指定的一致。 1234567891011121314151617181920212223242526272829CREATE TABLE IF NOT EXISTS person_1 (id int,info struct&lt;name:string,country:string&gt;) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' COLLECTION ITEMS TERMINATED BY ':' STORED AS TEXTFILE;创建一个文本文件test_struct.txt1,'dd':'jp'2,'ee':'cn'3,'gg':'jp'4,'ff':'cn'5,'tt':'jp'导入数据LOAD DATA LOCAL INPATH '/data/test_struct.txt' OVERWRITE INTO TABLE person_1;查询数据hive&gt; select * from person_1;OK1 &#123;\"name\":\"'dd'\",\"country\":\"'jp'\"&#125;2 &#123;\"name\":\"'ee'\",\"country\":\"'cn'\"&#125;3 &#123;\"name\":\"'gg'\",\"country\":\"'jp'\"&#125;4 &#123;\"name\":\"'ff'\",\"country\":\"'cn'\"&#125;5 &#123;\"name\":\"'tt'\",\"country\":\"'jp'\"&#125;Time taken: 0.046 seconds, Fetched: 5 row(s)hive&gt; select id,info.name,info.country from person_1 where info.name='dd';OK1 dd jpTime taken: 1.166 seconds, Fetched: 1 row(s) ARRAYARRAY表示一组相同数据类型的集合，下标从零开始，可以用下标访问 1234567891011121314151617181920212223CREATE TABLE IF NOT EXISTS array_1 (id int,name array&lt;STRING&gt;)ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' COLLECTION ITEMS TERMINATED BY ':' STORED AS TEXTFILE;导入数据LOAD DATA LOCAL INPATH '/data/test_array.txt' OVERWRITE INTO TABLE array_1;查询数据hive&gt; select * from array_1;OK1 [\"dd\",\"jp\"]2 [\"ee\",\"cn\"]3 [\"gg\",\"jp\"]4 [\"ff\",\"cn\"]5 [\"tt\",\"jp\"]Time taken: 0.041 seconds, Fetched: 5 row(s)hive&gt; select id,name[0],name[1] from array_1 where name[1]='cn';OK2 ee cn4 ff cnTime taken: 1.124 seconds, Fetched: 2 row(s) MAPMAP是一组键值对的组合，可以通过KEY访问VALUE，键值之间同样要在创建表时指定分隔符。 123456789101112131415161718192021222324CREATE TABLE IF NOT EXISTS map_1 (id int,name map&lt;STRING,STRING&gt;)ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' COLLECTION ITEMS TERMINATED BY ':' MAP KEYS TERMINATED BY ':'STORED AS TEXTFILE;加载数据LOAD DATA LOCAL INPATH '/data/test_map.txt' OVERWRITE INTO TABLE map_1;查询数据hive&gt; select * from map_1;OK1 &#123;\"name\":\"dd\",\"country\":\"jp\"&#125;2 &#123;\"name\":\"ee\",\"country\":\"cn\"&#125;3 &#123;\"name\":\"gg\",\"country\":\"jp\"&#125;4 &#123;\"name\":\"ff\",\"country\":\"cn\"&#125;5 &#123;\"name\":\"tt\",\"country\":\"jp\"&#125;Time taken: 0.038 seconds, Fetched: 5 row(s)select id,info['name'],info['country'] from map_1 where info['country']='cn';OK2 ee cn4 ff cnTime taken: 1.088 seconds, Fetched: 2 row(s) UINON TYPESHive除了支持STRUCT、ARRAY、MAP这些原生集合类型，还支持集合的组合，不支持集合里再组合多个集合。简单示例MAP嵌套ARRAY，手动设置集合格式的数据非常麻烦，建议采用INSERT INTO SELECT 形式构造数据再插入UNION表。 1234567891011121314151617181920212223242526272829303132333435创建DUAL表，插入一条记录，用于生成数据create table dual(d string);insert into dual values('X');创建UNION表CREATE TABLE IF NOT EXISTS uniontype_1 (id int,info map&lt;STRING,array&lt;STRING&gt;&gt;)ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' COLLECTION ITEMS TERMINATED BY '-'MAP KEYS TERMINATED BY ':'STORED AS TEXTFILE;插入数据insert overwrite table uniontype_1select 1 as id,map('english',array(99,21,33)) as info from dualunion allselect 2 as id,map('english',array(44,33,76)) as info from dualunion allselect 3 as id,map('english',array(76,88,66)) as info from dual;查询数据hive&gt; select * from uniontype_1;OK3 &#123;\"german\":[76,88,66]&#125;2 &#123;\"chinese\":[44,33,76]&#125;1 &#123;\"english\":[99,21,33]&#125;Time taken: 0.033 seconds, Fetched: 3 row(s)hive&gt; select * from uniontype_1 where info['english'][2]&gt;30;OK1 &#123;\"english\":[99,21,33]&#125;Time taken: 1.08 seconds, Fetched: 1 row(s)","categories":[{"name":"Hive","slug":"Hive","permalink":"http://yoursite.com/categories/Hive/"}],"tags":[{"name":"Hive","slug":"Hive","permalink":"http://yoursite.com/tags/Hive/"}]}]}